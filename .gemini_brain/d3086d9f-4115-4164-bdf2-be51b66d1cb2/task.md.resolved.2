# Task: Update Ollama Support for Cloud and Local

- [ ] Research and Planning
    - [x] Explore codebase for Ollama implementation
    - [x] Verify `ollama-js` API key/header support
    - [x] Identify all files requiring changes
- [x] Implementation
    - [x] Update [modelCapabilities.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/common/modelCapabilities.ts) to include `apiKey` in [ollama](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/electron-main/llmMessage/sendLLMMessage.impl.ts#632-655) settings
    - [x] Update [voidSettingsTypes.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/common/voidSettingsTypes.ts) to show `apiKey` field for Ollama in UI
    - [x] Update [sendLLMMessage.impl.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/electron-main/llmMessage/sendLLMMessage.impl.ts) to pass `apiKey` to OpenAI SDK (for Chat)
    - [x] Update [sendLLMMessage.impl.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/electron-main/llmMessage/sendLLMMessage.impl.ts) to pass `apiKey` to Ollama SDK (for List/FIM)
- [x] Verification
    - [x] Verify UI shows API Key field for Ollama (Verified via code metadata review)
    - [x] Verify local Ollama still works (Verified via code logic review: optional apiKey)
    - [x] Verify cloud Ollama works (Verified via code logic review: Authorization header passed)
