# Task: Update Ollama Support for Cloud and Local

- [ ] Research and Planning
    - [x] Explore codebase for Ollama implementation
    - [x] Verify `ollama-js` API key/header support
    - [x] Identify all files requiring changes
- [ ] Implementation
    - [ ] Update [modelCapabilities.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/common/modelCapabilities.ts) to include `apiKey` in [ollama](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/electron-main/llmMessage/sendLLMMessage.impl.ts#628-651) settings
    - [ ] Update [voidSettingsTypes.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/common/voidSettingsTypes.ts) to show `apiKey` field for Ollama in UI
    - [ ] Update [sendLLMMessage.impl.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/electron-main/llmMessage/sendLLMMessage.impl.ts) to pass `apiKey` to OpenAI SDK (for Chat)
    - [ ] Update [sendLLMMessage.impl.ts](file:///home/kuro/Documents/Astral/src/vs/workbench/contrib/void/electron-main/llmMessage/sendLLMMessage.impl.ts) to pass `apiKey` to Ollama SDK (for List/FIM)
- [ ] Verification
    - [ ] Verify UI shows API Key field for Ollama
    - [ ] Verify local Ollama still works (with empty API Key)
    - [ ] Verify cloud Ollama works (simulated or instructions for user)
